trigram_lda
trigram_lda[order(trigram_lda)]
unigram_lda[order(unigram_lda)]
barplot(x[1:10])
x
x <- trigram_lda[order(trigram_lda)]
y <- unigram_lda[order(unigram_lda)]
x
x[1:10,]
x[1:10]
barplot(x[1:10, 490:500])
str(x)
barplot(x[c(1:10),c(490:500)])
x[c(1:10,490:500)]
barplot(x[c(1:10,490:500)])
plot(x[c(1:10,490:500)], pch='')
table(unigram$speaker)
table(unigram$speaker)[1]
unigram_sd_mean_diff <- (meanShelby - meanSessions)/sqrt((varShelby/236) + (varSessions/1102))
table(trigram$speaker)
trigram_sd_mean_diff <- (TrimeanShelby - TrimeanSessions)/sqrt((TrivarShelby/236) + (TrivarSessions/1102))
trigram_sd_mean_diff
sd_mean_tri <- trigram_sd_mean_diff[order(trigram_sd_mean_diff)]
sd_mean_tri
colSums(unigram[unigram$speaker=="Shelby", -c(1,2)])
totShelbyU<- sum(ShelbyCol)
ShelbyCol <- colSums(unigram[unigram$speaker=="Shelby", -c(1,2)])
SessionsCol <- colSums(unigram[unigram$speaker=="Sessions", -c(1,2)])
totShelbyU<- sum(ShelbyCol)
totShelbyU
ncol(unigram)
piShelbyU<- (ShelbyCol + 1)/(sum(ShelbyCol) + 1001)
Sessions_p<- (SessionsCol + 1)/(sum(SessionsCol) + 1001)
VarLogOdds_uni <- (1/(ShelbyCol + 1)) + (1/SessionsCol + 1))
VarLogOdds_uni <- (1/(ShelbyCol + 1)) + (1/(SessionsCol + 1))
ShelbyCol <- colSums(unigram[unigram$speaker=="Shelby", -c(1,2)])
SessionsCol <- colSums(unigram[unigram$speaker=="Sessions", -c(1,2)])
Shelby_p<- (ShelbyCol + 1)/(sum(ShelbyCol) + 1001)
Sessions_p<- (SessionsCol + 1)/(sum(SessionsCol) + 1001)
LogOdds_uni <- log(Shelby_p/ (1- Shelby_p)) - log(Sessions_p/ (1-Sessions_p))
VarLogOdds_uni <- (1/(ShelbyCol + 1)) + (1/(SessionsCol + 1))
sdLogOdds<- LogOdds_uni/ sqrt(VarLogOdds_uni)
sdLogOdds
ShelbyCol.tri <- colSums(trigram[trigram$speaker=="Shelby", -c(1,2)])
SessionsCol.tri <- colSums(trigram[trigram$speaker=="Sessions", -c(1,2)])
ncol(trigram)
ShelbyCol.tri <- colSums(trigram[trigram$speaker=="Shelby", -c(1,2)])
SessionsCol.tri <- colSums(trigram[trigram$speaker=="Sessions", -c(1,2)])
Shelby_p.tri<- (ShelbyCol.tri + 1)/(sum(ShelbyCol.tri) + 501)
Sessions_p.tri<- (SessionsCol.tri + 1)/(sum(SessionsCol.tri) + 501)
LogOdds_tri <- log(Shelby_p.tri/ (1- Shelby_p.tri)) - log(Sessions_p.tri/ (1-Sessions_p.tri))
VarLogOdds_tri <- (1/(ShelbyCol.tri + 1)) + (1/(SessionsCol.tri + 1))
sdLogOdds.tri<- LogOdds_tri/ sqrt(VarLogOdds_tri)
sdLogOdds.tri
lda_tri <- trigram_lda[order(trigram_lda)]
lda_uni <- unigram_lda[order(unigram_lda)]
sd_mean_uni <- unigram_sd_mean_diff[order(unigram_sd_mean_diff)]
sd_mean_tri <- trigram_sd_mean_diff[order(trigram_sd_mean_diff)]
sdLogOdds <- sdLogOdds[order(sdLogOdds)]
sdLogOdds.tri <- sdLogOdds.tri[order(sdLogOdds.tri)]
sdLogOdds
plot(lda_tri[c(1:10,490:500)], pch="", main="LDA")
sdLogOdds <- sdLogOdds[order(sdLogOdds)]
sdLogOdds.tri <- sdLogOdds.tri[order(sdLogOdds.tri)]
sdLogOdds[c(1:10, 490:500)]
index<- seq(1, 20, 1)
plot(lda_tri[c(1:10,490:500)],index,xlab="weight",ylab="", pch="", main="Most discriminating words in LDA")
plot(lda_tri[c(1:10,490:500)],index,xlab="weight",ylab="", pch="", main="Most discriminating words in LDA")
lda_tri[c(1:10,490:500)]
plot(lda_tri[c(1:10,490:500)],index,xlab="weight",ylab="", pch="", main="Most discriminating words in LDA")
length(lda_tri[c(1:10,490:500)])
length(index)
index<- seq(1, 21, 1)
plot(lda_tri[c(1:10,490:500)],index,xlab="weight",ylab="", pch="", main="Most discriminating words in LDA")
text(lda_tri[c(1:10,490:500)], index , label=names(lda_tri[c(1:10,490:500)]), cex=.7)
text(lda_tri[c(1:10,490:500)], index , label=names(lda_tri[c(1:10,490:500)]), cex=.7, col="red")
text(lda_uni[c(1:10,490:500)], index , label=names(lda_uni[c(1:10,490:500)]), cex=.7, col="blue")
lda_uni[c(1:10,490:500)
]
text(lda_uni[c(1:10,990:1000)], index , label=names(lda_uni[c(1:10,990:1000)]), cex=.7, col="blue")
plot(lda_tri[c(1:10,490:500)],index,xlab="weight",ylab="", pch="", main="Most discriminating words in LDA")
text(lda_tri[c(1:10,490:500)], index , label=names(lda_tri[c(1:10,490:500)]), cex=.7, col="red")
text(lda_uni[c(1:10,990:1000)], index , label=names(lda_uni[c(1:10,990:1000)]), cex=.7, col="blue")
lda_uni[c(1:10,990:1000)]
plot(lda_tri[c(1:10,490:500)],index,xlab="weight",ylab="", pch="", main="Most discriminating words in LDA")
text(lda_tri[c(1:10,490:500)], index , label=names(lda_tri[c(1:10,490:500)]), cex=.6, col="red")
plot(lda_tri[c(1:10,490:500)],index,xlab="weight",xlim=c(-15, 170),ylab="", pch="", main="Most discriminating words in LDA")
text(lda_tri[c(1:10,490:500)], index , label=names(lda_tri[c(1:10,490:500)]), cex=.6, col="red")
plot(sd_mean_tri[c(1:10,490:500)],index,  pch='', main="Most discriminating words in \n Standardized Mean difference")
text(sd_mean_tri[c(1:10,490:500)], index , label=names(sd_mean_tri[c(1:10,490:500)]), cex=.6, col="red")
plot(sd_mean_tri[c(1:10,490:500)],index, xlim=c(-25, 10), pch='', main="Most discriminating words in \n Standardized Mean difference")
text(sd_mean_tri[c(1:10,490:500)], index , label=names(sd_mean_tri[c(1:10,490:500)]), cex=.6, col="red")
plot(sd_mean_tri[c(1:10,490:500)],index, xlim=c(-25, 10), ylab="",xlab="weight,pch='', main="Most discriminating words in \n Standardized Mean difference")
text(sd_mean_tri[c(1:10,490:500)], index , label=names(sd_mean_tri[c(1:10,490:500)]), cex=.6, col="red")
plot(y[c(1:10,490:500)], pch='', main="Standardized Log Odds")
dev.off()
plot(sd_mean_tri[c(1:10,490:500)],index, xlim=c(-25, 10), ylab="",xlab="weight",pch='', main="Most discriminating words in \n Standardized Mean difference")
text(sd_mean_tri[c(1:10,490:500)], index , label=names(sd_mean_tri[c(1:10,490:500)]), cex=.6, col="red")
plot(sdLogOdds.tri[c(1:10,490:500)],index, ylab="",xlab="weight",pch='', main="Most discriminating words in \n Standardized Log Odds")
text(sdLogOdds.tri[c(1:10,490:500)], index , label=names(sdLogOdds.tri[c(1:10,490:500)]), cex=.6, col="red")
plot(sdLogOdds.tri[c(1:10,490:500)],index,xlim=c(-10, 5),  ylab="",xlab="weight",pch='', main="Most discriminating words in \n Standardized Log Odds")
text(sdLogOdds.tri[c(1:10,490:500)], index , label=names(sdLogOdds.tri[c(1:10,490:500)]), cex=.6, col="red")
pdf(file="Plot_measure_tri.pdf")
par(mfrow=c(3,1))
index<- seq(1, 21, 1)
plot(lda_tri[c(1:10,490:500)],index,xlab="weight",xlim=c(-15, 170),ylab="", pch="", main="Most discriminating words in LDA")
text(lda_tri[c(1:10,490:500)], index , label=names(lda_tri[c(1:10,490:500)]), cex=.6, col="red")
plot(sd_mean_tri[c(1:10,490:500)],index, xlim=c(-25, 10), ylab="",xlab="weight",pch='', main="Most discriminating words in \n Standardized Mean difference")
text(sd_mean_tri[c(1:10,490:500)], index , label=names(sd_mean_tri[c(1:10,490:500)]), cex=.6, col="red")
plot(sdLogOdds.tri[c(1:10,490:500)],index,xlim=c(-10, 5),  ylab="",xlab="weight",pch='', main="Most discriminating words in \n Standardized Log Odds")
text(sdLogOdds.tri[c(1:10,490:500)], index , label=names(sdLogOdds.tri[c(1:10,490:500)]), cex=.6, col="red")
dev.off()
par(mfrow=c(3,1))
index<- seq(1, 21, 1)
plot(lda_uni[c(1:10,490:500)],index,xlab="weight",ylab="", pch="", main="Most discriminating words in LDA")
text(lda_uni[c(1:10,490:500)], index , label=names(lda_uni[c(1:10,490:500)]), cex=.6, col="red")
plot(sd_mean_uni[c(1:10,490:500)],index, ylab="",xlab="weight",pch='', main="Most discriminating words in \n Standardized Mean difference")
text(sd_mean_uni[c(1:10,490:500)], index , label=names(sd_mean_uni[c(1:10,490:500)]), cex=.6, col="red")
plot(sdLogOdds[c(1:10,490:500)],index,ylab="",xlab="weight",pch='', main="Most discriminating words in \n Standardized Log Odds")
text(sdLogOdds[c(1:10,490:500)], index , label=names(sdLogOdds[c(1:10,490:500)]), cex=.6, col="red")
par(mfrow=c(3,1))
index<- seq(1, 21, 1)
plot(lda_uni[c(1:10,490:500)],index,xlab="weight",ylab="", pch="", main="Most discriminating words in LDA")
text(lda_uni[c(1:10,490:500)], index , label=names(lda_uni[c(1:10,490:500)]), cex=.6, col="red")
plot(sd_mean_uni[c(1:10,490:500)],index, ylab="",xlab="weight",pch='', main="Most discriminating words in Standardized Mean difference")
text(sd_mean_uni[c(1:10,490:500)], index , label=names(sd_mean_uni[c(1:10,490:500)]), cex=.6, col="red")
plot(sdLogOdds[c(1:10,490:500)],index,ylab="",xlab="weight",pch='', main="Most discriminating words in Standardized Log Odds")
text(sdLogOdds[c(1:10,490:500)], index , label=names(sdLogOdds[c(1:10,490:500)]), cex=.6, col="red")
pdf(file="Plot_measure_uni.pdf")
par(mfrow=c(3,1))
index<- seq(1, 21, 1)
plot(lda_uni[c(1:10,490:500)],index,xlab="weight",ylab="", pch="", main="Most discriminating words in LDA")
text(lda_uni[c(1:10,490:500)], index , label=names(lda_uni[c(1:10,490:500)]), cex=.6, col="red")
plot(sd_mean_uni[c(1:10,490:500)],index, ylab="",xlab="weight",pch='', main="Most discriminating words in Standardized Mean difference")
text(sd_mean_uni[c(1:10,490:500)], index , label=names(sd_mean_uni[c(1:10,490:500)]), cex=.6, col="red")
plot(sdLogOdds[c(1:10,490:500)],index,ylab="",xlab="weight",pch='', main="Most discriminating words in Standardized Log Odds")
text(sdLogOdds[c(1:10,490:500)], index , label=names(sdLogOdds[c(1:10,490:500)]), cex=.6, col="red")
dev.off()
par(mfrow=c(3,1))
index<- seq(1, 21, 1)
plot(lda_tri[c(1:10,490:500)],index,xlab="weight",xlim=c(-15, 170),ylab="", pch="", main="Most discriminating words in LDA")
text(lda_tri[c(1:10,490:500)], index , label=names(lda_tri[c(1:10,490:500)]), cex=.6, col="red")
plot(sd_mean_tri[c(1:10,490:500)],index, xlim=c(-25, 10), ylab="",xlab="weight",pch='', main="Most discriminating words in \n Standardized Mean difference")
text(sd_mean_tri[c(1:10,490:500)], index , label=names(sd_mean_tri[c(1:10,490:500)]), cex=.6, col="red")
plot(sdLogOdds.tri[c(1:10,490:500)],index,xlim=c(-10, 5),  ylab="",xlab="weight",pch='', main="Most discriminating words in \n Standardized Log Odds")
text(sdLogOdds.tri[c(1:10,490:500)], index , label=names(sdLogOdds.tri[c(1:10,490:500)]), cex=.6, col="red")
pdf(file="Plot_measure_tri.pdf")
par(mfrow=c(3,1))
index<- seq(1, 21, 1)
plot(lda_tri[c(1:10,490:500)],index,xlab="weight",xlim=c(-15, 170),ylab="", pch="", main="Most discriminating words in LDA")
text(lda_tri[c(1:10,490:500)], index , label=names(lda_tri[c(1:10,490:500)]), cex=.6, col="red")
plot(sd_mean_tri[c(1:10,490:500)],index, xlim=c(-25, 10), ylab="",xlab="weight",pch='', main="Most discriminating words in Standardized Mean difference")
text(sd_mean_tri[c(1:10,490:500)], index , label=names(sd_mean_tri[c(1:10,490:500)]), cex=.6, col="red")
plot(sdLogOdds.tri[c(1:10,490:500)],index,xlim=c(-10, 5),  ylab="",xlab="weight",pch='', main="Most discriminating words in Standardized Log Odds")
text(sdLogOdds.tri[c(1:10,490:500)], index , label=names(sdLogOdds.tri[c(1:10,490:500)]), cex=.6, col="red")
dev.off()
ShelbyWords<- sample(which(trigram$speaker=="Shelby"), 100, replace=F)
SessionsWords<- sample(which(trigram$speaker=="Sessions"), 100, replace=F)
ShelbyWords
trigram[index,]
head(trigram[index,])
which(trigram$speaker=="Shelby")
ShelbyWords <- trigram[index,]
View(ShelbyWords)
index<- sample(which(trigram$speaker=="Shelby"), 100, replace=F)
ShelbyWords <- trigram[index,]
Sessionwords <- trigram[index,]
SessionWords <- trigram[index,]
View(SessionWords)
index<- sample(which(trigram$speaker=="Shelby"), 100, replace=F)
ShelbyWords <- trigram[index,]
index<- sample(which(trigram$speaker=="Sessions"), 100, replace=F)
SessionWords <- trigram[index,]
distSample<- c(index, index)
ds<- trigram[distSample,]
View(ds)
colnames(ds)
distSample
View(ds)
ed<- matrix(nrow=200, ncol=200)
ed
index.1<- sample(which(trigram$speaker=="Shelby"), 100, replace=F)
index.2<- sample(which(trigram$speaker=="Sessions"), 100, replace=F)
index<- c(index.1, index.2)
TrigramWords<- trigram[index,]
ids<-subset(TrigramWords[,1:2])
TrigramWords<- as.matrix(TrigramWords[,-c(1,2)])
View(trigram_rate)
View(TrigramWords)
which(colSums(TrigramWords)==0
ds<-ds[,-c(which(colSums(ds)==0))]
# create matrices
# Euclidean distance between documents
distMatrix<- matrix(nrow=200, ncol=200)
EDistance<- function(x, y){
return(sqrt(sum((x-y)^2)))
}
for (m in 1:nrow(ds)){
for (n in 1:nrow(ds)){
if (is.na(distMatrix[m,n])==T){
a<- euclidean(ds[m,], ds[n,])
distMatrix[m,n]<- a
distMatrix[n,m]<- a
}
}
}
which(colSums(TrigramWords)==0)
missing <- which(colSums(TrigramWords)==0)
TrigramWords<-TrigramWords[,-missing]
distMatrix<- matrix(nrow=200, ncol=200)
EDistance<- function(x, y){
return(sqrt(sum((x-y)^2)))
}
for (i in 1:nrow(TrigramWords)){
for (j in 1:nrow(TrigramWords)){
if (is.na(distMatrix[i,j])==T){
ds<- euclidean(TrigramWords[i,], TrigramWords[j,])
distMatrix[i,j]<- ds
distMatrix[j,i]<- ds
}
}
}
distMatrix<- matrix(nrow=200, ncol=200)
EDistance<- function(x, y){
return(sqrt(sum((x-y)^2)))
}
for (i in 1:nrow(TrigramWords)){
for (j in 1:nrow(TrigramWords)){
if (is.na(distMatrix[i,j])==T){
ds<- EDistance(TrigramWords[i,], TrigramWords[j,])
distMatrix[i,j]<- ds
distMatrix[j,i]<- ds
}
}
}
distMatrix
tfidfMatrix<-matrix(nrow=200, ncol=200)
tfidfFun<- function(x){
return(log(200/length(which(x>0))))
}
apply(TrigramWords, 2, tfidfFun)
idf <- as.matrix(t(apply(TrigramWords, 1, function(x) x*apply(TrigramWords, 2, tfidfFun))
ds_idf<- as.matrix(t(apply(ds, 1, function(x) x*idf)))
edWithTfidf<- as.matrix(dist(ds_idf, method="euclidean"))
idf <- as.matrix(t(apply(TrigramWords, 1, function(x) x*apply(TrigramWords, 2, tfidfFun))))
idf
as.matrix(dist(idf, method="euclidean"))
tfidfMatrix<-as.matrix(dist(idf, method="euclidean"))
tfidfFun<- function(x){
return(log(200/length(which(x>0))))
}
idf <- as.matrix(t(apply(TrigramWords, 1, function(x) x*apply(TrigramWords, 2, tfidfFun))))
tfidfMatrix<-as.matrix(dist(idf, method="euclidean"))
CosineMatrix<- matrix(nrow=200, ncol=200)
CosineMatrix<- matrix(nrow=200, ncol=200)
cosineFun<- function(x, y){
return( sum(x*y)/ sqrt( sum(x^2)* sum(y^2)))
}
CosineMatrix<- matrix(nrow=200, ncol=200)
cosineFun<- function(x, y){
return( sum(x*y)/ sqrt(sum(x^2)*sum(y^2)))
}
for (i in 1:nrow(TrigramWords)){
for (j in 1:nrow(TrigramWords)){
s <- cosineFun(TrigramWords[i,], TrigramWords[j,])
CosineMatrix[i, j]<- s
CosineMatrix[j, i]<- s
}
}
CosineMatrix
tfidfMatrix
library(lsa)
install.packages("lsa")
library(lsa)
TrigramWords
for (m in 1:nrow(TrigramWords)){
for (n in 1:nrow(TrigramWords)){
a<- cosine(TrigramWords[m,], TrigramWords[n,])
CosineMatrix[m, n]<- a
CosineMatrix[n, m]<- a
}
}
CosineMatrix
a
cosine(TrigramWords[5,], TrigramWords[5,])
nrow(TrigramWords)
CosineMatrix<- matrix(nrow=200, ncol=200)
library(lsa)
for (i in 1:200){
for (j in 1:200){
a<- cosine(TrigramWords[i,], TrigramWords[j,])
CosineMatrix[i, j]<- a
CosineMatrix[j, i]<- a
}
}
CosineMatrix # check
TrigramWords
is.na(TrigramWords)
which(is.na(TrigramWords)==TRUE)
idf
CosineMatrix2<- matrix(nrow=200, ncol=200)
for (i in 1:nrow(idf)){
for (j in 1:nrow(idf)){
theta <- cosine(idf[i,], idf[j,])
CosineMatrix2[i, j]<- theta
CosineMatrix2[j, i]<- theta
}
}
CosineMatrix2
TrigramWords
KernMatrix <- matrix(nrow=200, ncol=200)
KernMatrix <- matrix(nrow=200, ncol=200)
for (i in 1:200){
KernMatrix[i,]<- TrigramWords[i,]/sum(TrigramWords[i,])
}
TrigramWords[1,]/sum(TrigramWords[1,])
sum(TrigramWords[1,]
)
KernMatrix <- NA
for (i in 1:200){
KernMatrix[i,]<- TrigramWords[i,]/sum(TrigramWords[i,])
}
str(TrigramWords)
index.1<- sample(which(trigram$speaker=="Shelby"), 100, replace=F)
index.2<- sample(which(trigram$speaker=="Sessions"), 100, replace=F)
index<- c(index.1, index.2)
TrigramWords<- trigram[index,]
ids<-subset(TrigramWords[,1:2])
ids$file <- as.character(ids$file)
ids$speaker <- as.character(ids$speaker)
TrigramWords<- as.matrix(TrigramWords[,-c(1,2)])
missing <- which(colSums(TrigramWords)==0)
TrigramWords<-TrigramWords[,-missing]
500-457
distMatrix<- matrix(nrow=200, ncol=200)
EDistance<- function(x, y){
return(sqrt(sum((x-y)^2)))
}
for (i in 1:nrow(TrigramWords)){
for (j in 1:nrow(TrigramWords)){
if (is.na(distMatrix[i,j])==T){
ds<- EDistance(TrigramWords[i,], TrigramWords[j,])
distMatrix[i,j]<- ds
distMatrix[j,i]<- ds
}
}
}
distMatrix # check
tfidfFun<- function(x){
return(log(200/length(which(x>0))))
}
idf <- as.matrix(t(apply(TrigramWords, 1, function(x) x*apply(TrigramWords, 2, tfidfFun))))
tfidfMatrix<-as.matrix(dist(idf, method="euclidean"))
tfidfMatrix # check
CosineMatrix<- matrix(nrow=200, ncol=200)
library(lsa)
for (i in 1:200){
for (j in 1:200){
theta<- cosine(TrigramWords[i,], TrigramWords[j,])
CosineMatrix[i, j]<- theta
CosineMatrix[j, i]<- theta
}
}
CosineMatrix # check
CosineMatrix2<- matrix(nrow=200, ncol=200)
for (i in 1:nrow(idf)){
for (j in 1:nrow(idf)){
theta <- cosine(idf[i,], idf[j,])
CosineMatrix2[i, j]<- theta
CosineMatrix2[j, i]<- theta
}
}
CosineMatrix2 # check
nrow(TrigramWords)
normalized <- TrigramWords
for (i in 1:200){
normalized[i,]<- TrigramWords[i,]/sum(TrigramWords[i,])
}
normalized # check
sigma <-c(0, 1, 10, 50, 100)
sigma[1]
sigma[2]
for(i in 1:5){ # Start the loop
Gaussian[,,i] <- exp(-(as.matrix(dist(normalized)))/sigma[i])
}
result <- vector("list", 5)
result <- vector("list", 5)
for(i in 1:5){ # Start the loop
result[i] <- exp(-(as.matrix(dist(normalized)))/sigma[i])
}
result <- vector("list", 5)
for(i in 1:5){ # Start the loop
result[[i]] <- exp(-(as.matrix(dist(normalized)))/sigma[i])
}
result[1]
result[2]
result[3]
result[4]
result[5]
tfidf <- apply(normalized, 2, tfidfFun)
normalized_tfidf<- as.matrix(t(apply(normalized, 1, function(x) x*tfidf)))
sigma <-c(0, 1, 10, 50, 100) # apply different values of sigma
gauss <- vector("list", 5)
for(i in 1:5){ # Start the loop
gauss[[i]] <- exp(-(as.matrix(dist(normalized_tfidf)))/sigma[i])
}
gauss[1] # check
gauss[2] # check
max(CosineMatrix2)
max(tfidfMatrix)
max(distMatrix)
max(gauss)
max(gauss[5])
gauss[5]
max(gauss[5])
matrix5 <- gauss[5]
max(matrix5)
matrix5 <- as.matrix(gauss[5])
max(matrix5)
which(tfidfMatrix==61.54602)
rm(list=ls())
setwd('~/Dropbox/2017_Classes/Text-Analysis/WUSTL/HW/HW2/')
unigram <- read.csv("unigrams1000.csv")
trigram <- read.csv("trigrams500.csv")
str(unigram)
str(trigram)
subuni <- unigram[,-c(1,2)]
for (i in 1:nrow(unigram)){
subuni[i,]<- subuni[i,]/(sum(subuni[i,]))
}
unigram_rate <- cbind(unigram[,c(1,2)], subuni)
View(trigram)
View(unigram_rate)
sum(subuni[1,])
subuni[1,]
subtri <- trigram[,-c(1,2)]
for (i in 1:nrow(trigram)){
subtri[i,]<- subtri[i,]/(sum(subtri[i,]))
}
trigram_rate <- cbind(trigram[,c(1,2)], subtri)
meanShelby<-apply(unigram_rate[unigram_rate$speaker=="Shelby", -c(1,2)], 2, mean,na.rm=T)
meanSessions <-apply(unigram_rate[unigram_rate$speaker=="Sessions", -c(1,2)], 2, mean,na.rm=T)
varShelby<-apply(unigram_rate[unigram_rate$speaker=="Shelby", -c(1,2)], 2, var,na.rm=T)
varSessions <-apply(unigram_rate[unigram_rate$speaker=="Sessions", -c(1,2)], 2, var,na.rm=T)
TrimeanShelby<-apply(trigram_rate[trigram_rate$speaker=="Shelby", -c(1,2)], 2, mean, na.rm=T)
TrimeanSessions <-apply(trigram_rate[trigram_rate$speaker=="Sessions", -c(1,2)], 2, mean,na.rm=T)
TrivarShelby<-apply(trigram_rate[trigram_rate$speaker=="Shelby", -c(1,2)], 2, var,na.rm=T)
TrivarSessions <-apply(trigram_rate[trigram_rate$speaker=="Sessions", -c(1,2)], 2, var,na.rm=T)
unigram_lda <- (meanShelby-meanSessions)/(varShelby-varSessions)
unigram_lda
trigram_lda <- (TrimeanShelby-TrimeanSessions)/(TrivarShelby-TrivarSessions)
trigram_lda
table(unigram$speaker)
unigram_sd_mean_diff <- (meanShelby - meanSessions)/sqrt((varShelby/236) + (varSessions/1102))
trigram_sd_mean_diff <- (TrimeanShelby - TrimeanSessions)/sqrt((TrivarShelby/236) + (TrivarSessions/1102))
ShelbyCol <- colSums(unigram[unigram$speaker=="Shelby", -c(1,2)])
SessionsCol <- colSums(unigram[unigram$speaker=="Sessions", -c(1,2)])
Shelby_p<- (ShelbyCol + 1)/(sum(ShelbyCol) + 1001)
Sessions_p<- (SessionsCol + 1)/(sum(SessionsCol) + 1001)
LogOdds_uni <- log(Shelby_p/ (1- Shelby_p)) - log(Sessions_p/ (1-Sessions_p))
VarLogOdds_uni <- (1/(ShelbyCol + 1)) + (1/(SessionsCol + 1))
sdLogOdds<- LogOdds_uni/ sqrt(VarLogOdds_uni)
ShelbyCol.tri <- colSums(trigram[trigram$speaker=="Shelby", -c(1,2)])
SessionsCol.tri <- colSums(trigram[trigram$speaker=="Sessions", -c(1,2)])
Shelby_p.tri<- (ShelbyCol.tri + 1)/(sum(ShelbyCol.tri) + 501)
Sessions_p.tri<- (SessionsCol.tri + 1)/(sum(SessionsCol.tri) + 501)
LogOdds_tri <- log(Shelby_p.tri/ (1- Shelby_p.tri)) - log(Sessions_p.tri/ (1-Sessions_p.tri))
VarLogOdds_tri <- (1/(ShelbyCol.tri + 1)) + (1/(SessionsCol.tri + 1))
sdLogOdds.tri<- LogOdds_tri/ sqrt(VarLogOdds_tri)
lda_tri <- trigram_lda[order(trigram_lda)]
lda_uni <- unigram_lda[order(unigram_lda)]
sd_mean_uni <- unigram_sd_mean_diff[order(unigram_sd_mean_diff)]
sd_mean_tri <- trigram_sd_mean_diff[order(trigram_sd_mean_diff)]
sdLogOdds <- sdLogOdds[order(sdLogOdds)]
sdLogOdds.tri <- sdLogOdds.tri[order(sdLogOdds.tri)]
index<- seq(1, 21, 1)
plot(lda_tri[c(1:10,490:500)],index,xlab="weight",xlim=c(-15, 170),ylab="", pch="", main="Most discriminating words in LDA")
text(lda_tri[c(1:10,490:500)], index , label=names(lda_tri[c(1:10,490:500)]), cex=.6, col="red")
plot(sd_mean_tri[c(1:10,490:500)],index, xlim=c(-25, 10), ylab="",xlab="weight",pch='', main="Most discriminating words in Standardized Mean difference")
text(sd_mean_tri[c(1:10,490:500)], index , label=names(sd_mean_tri[c(1:10,490:500)]), cex=.6, col="red")
plot(sdLogOdds.tri[c(1:10,490:500)],index,xlim=c(-10, 5),  ylab="",xlab="weight",pch='', main="Most discriminating words in Standardized Log Odds")
text(sdLogOdds.tri[c(1:10,490:500)], index , label=names(sdLogOdds.tri[c(1:10,490:500)]), cex=.6, col="red")
par(mfrow=c(3,1))
index<- seq(1, 21, 1)
plot(lda_tri[c(1:10,490:500)],index,xlab="weight",xlim=c(-15, 170),ylab="", pch="", main="Most discriminating words in LDA")
text(lda_tri[c(1:10,490:500)], index , label=names(lda_tri[c(1:10,490:500)]), cex=.6, col="red")
plot(sd_mean_tri[c(1:10,490:500)],index, xlim=c(-25, 10), ylab="",xlab="weight",pch='', main="Most discriminating words in Standardized Mean difference")
text(sd_mean_tri[c(1:10,490:500)], index , label=names(sd_mean_tri[c(1:10,490:500)]), cex=.6, col="red")
plot(sdLogOdds.tri[c(1:10,490:500)],index,xlim=c(-10, 5),  ylab="",xlab="weight",pch='', main="Most discriminating words in Standardized Log Odds")
par(mfrow=c(3,1))
index<- seq(1, 21, 1)
plot(lda_tri[c(1:10,490:500)],index,xlab="weight",xlim=c(-15, 170),ylab="", pch="", main="Most discriminating words in LDA")
par(mfrow=c(3,1))
index<- seq(1, 21, 1)
plot(lda_tri[c(1:10,490:500)],index,xlab="weight",xlim=c(-15, 170),ylab="", pch="", main="Most discriminating words in LDA")
text(lda_tri[c(1:10,490:500)], index , label=names(lda_tri[c(1:10,490:500)]), cex=.6, col="red")
plot(sd_mean_tri[c(1:10,490:500)],index, xlim=c(-25, 10), ylab="",xlab="weight",pch='', main="Most discriminating words in Standardized Mean difference")
text(sd_mean_tri[c(1:10,490:500)], index , label=names(sd_mean_tri[c(1:10,490:500)]), cex=.6, col="red")
plot(sdLogOdds.tri[c(1:10,490:500)],index,xlim=c(-10, 5),  ylab="",xlab="weight",pch='', main="Most discriminating words in Standardized Log Odds")
text(sdLogOdds.tri[c(1:10,490:500)], index , label=names(sdLogOdds.tri[c(1:10,490:500)]), cex=.6, col="red")
index.1<- sample(which(trigram$speaker=="Shelby"), 100, replace=F)
index.2<- sample(which(trigram$speaker=="Sessions"), 100, replace=F)
# create matrix
index<- c(index.1, index.2)
TrigramWords<- trigram[index,]
ids<-subset(TrigramWords[,1:2])
ids$file <- as.character(ids$file)
ids$speaker <- as.character(ids$speaker)
# remove ids
TrigramWords<- as.matrix(TrigramWords[,-c(1,2)])
# remove missing columns (words=0)
TrigramWords <- TrigramWords[,which(!apply(TrigramWords,2,FUN = function(x){all(x == 0)}))] # 43 columns will be omitted
