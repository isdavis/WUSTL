#null hypothesis:
#proportion of males for Obama - proportion of females for Obama == 0
#alternative hypothesis:
#proportion of males for Obama - proportion of females for Obama != 0
prop.obama.male <- my.crosstab[2,1]/sum(my.crosstab[,1]) #proportion of males supporting Obama
prop.obama.female <- my.crosstab[2,2]/sum(my.crosstab[,2]) #proportion of females supporting Obama
n.male <- sum(my.crosstab[,1]) #total number of males
n.female <- sum(my.crosstab[,2]) #total number of females
n <- n.male + n.female #total number of respondents
n.obama <- sum(my.crosstab[2,]) #total number of Obama supporters
n.mccain <- sum(my.crosstab[1,]) #total number of McCain supporters
#side note: a quick intro rep(), which just repeats an expression a particular number of times
rep(1, 10)
rep("A", 10)
# We want to simulate data under the null hypothesis, just as before, but the process is a little more involved.
# We want to have the total numbers of Obama and McCain supporters, and the total number of females and males,
# remain the same, but we want to ensure that gender is indendent of support for Obama or McCain.
# Our logic for simulating the data is as follows:
# We create a "box" containing the same numbers of Obama and McCain supporters that were in the true sample
# If support for Obama is indendent of gender, then selecting a bunch of folks of the same gender should be like
# sampling with replacement from that box (recall sampling with replacement from the previous lab).
# Therefore, we will draw numbers of male (female) respondents by sampling with replacement a number of
# respondents from that box that is equal to the true number of male (female) respondents in the data.
#Thus, in expectation, we ought to get the same proportion of male Obama supporters as female Obama supporters.
#THis code is below:
#we will do this 1,000,000 times so we will create a vector to store that many results
# (this will take a minute)
simulation.results <- numeric(1000000)
for(i in 1:100000){ #this tells R that we want to do this 1,000,000 times
box <- c(rep(1, n.obama), rep(0, n.mccain)) #this creates our box of the appropriate numbers of obama/mccain supporters
male.sample <- sample(x=box, size=n.male, replace=TRUE) #our male sample is a random sample (w/replacement) from that box
female.sample <- sample(x=box, size=n.female, replace=TRUE) #same with our female sample
male.sample.proportion <- mean(male.sample) #compute the proportion of Obama supporters in the male sample
female.sample.proportion <- mean(female.sample) #same with female supporters
diff <- male.sample.proportion - female.sample.proportion #now we take the difference between the male and female supporters
simulation.results[i] <- diff #and record that in the appropriate position in our vector
} #end of loop
#let's look at the simulated distribution
hist(simulation.results)
#compute the actual difference in proportions from the data, for comparison
real.diff <- prop.obama.male - prop.obama.female
#now we will perform our hypothesis tests by computing the proportion of simulated datasets where
#the differences in the male-female proportions of Obama supporters is as different from zero as
#in our actual sample
our.crosstab.test <- abs(simulation.results) >= abs(real.diff)
#The proportion of cases where this occurs is an extremely small number, indicating that our data
# is extremely unlikely under the null hypothesis.
mean(our.crosstab.test)
# Therefore, we would reject the null hypothesis that gender is unrelated to support for Obama
rm(list=ls())
simulated.coin.data <- rbinom(n=10000, size=1000, prob=1/2)
mean(simulated.coin.data)
hist(simulated.coin.data, main="Distribution of the simulated data")
abline(v=500, lwd=4, col="red", lty=2)
our.twotailed.test <- abs(simulated.coin.data - 500) >= 30 #a logical variable
our.twotailed.test
mean(our.twotailed.test)
our.onetailed.test <- simulated.coin.data >= 530
mean(our.onetailed.test)
our.onetailed.test <- simulated.coin.data <= 470
mean(our.onetailed.test)
my.crosstab <- matrix(c(682, 752, 697, 1058), nrow=2, ncol=2, byrow=TRUE)
row.names(my.crosstab) <- c("McCain", "Obama")
colnames(my.crosstab) <- c("Male", "Female")
my.crosstab
my.crosstab[2,1]
prop.obama.male <- my.crosstab[2,1]/sum(my.crosstab[,1]) #proportion of males supporting Obama
prop.obama.female <- my.crosstab[2,2]/sum(my.crosstab[,2]) #proportion of females supporting Obama
n.male <- sum(my.crosstab[,1]) #total number of males
n.female <- sum(my.crosstab[,2]) #total number of females
n.male
n.female
n <- n.male + n.female #total number of respondents
n
n.obama <- sum(my.crosstab[2,]) #total number of Obama supporters
n.mccain <- sum(my.crosstab[1,]) #total number of McCain supporters
simulation.results <- numeric(1000000)
simulation.results <- numeric(1000000)
for(i in 1:100000){ #this tells R that we want to do this 1,000,000 times
box <- c(rep(1, n.obama), rep(0, n.mccain)) #this creates our box of the appropriate numbers of obama/mccain supporters
male.sample <- sample(x=box, size=n.male, replace=TRUE) #our male sample is a random sample (w/replacement) from that box
female.sample <- sample(x=box, size=n.female, replace=TRUE) #same with our female sample
male.sample.proportion <- mean(male.sample) #compute the proportion of Obama supporters in the male sample
female.sample.proportion <- mean(female.sample) #same with female supporters
diff <- male.sample.proportion - female.sample.proportion #now we take the difference between the male and female supporters
simulation.results[i] <- diff #and record that in the appropriate position in our vector
} #end of loop
hist(simulation.results)
real.diff <- prop.obama.male - prop.obama.female
our.crosstab.test <- abs(simulation.results) >= abs(real.diff)
mean(our.crosstab.test)
1000
simulated.coin.data <- rbinom(n=10000, size=1000, prob=1/2)
mean(simulated.coin.data)
hist(simulated.coin.data, main="Distribution of the simulated data")
abline(v=500, lwd=4, col="red", lty=2)
our.twotailed.test <- abs(simulated.coin.data - 500) >= 30 #a logical variable
our.twotailed.test
mean(our.twotailed.test)
our.onetailed.test <- simulated.coin.data >= 530
mean(our.onetailed.test)
my.crosstab <- matrix(c(682, 752, 697, 1058), nrow=2, ncol=2, byrow=TRUE)
row.names(my.crosstab) <- c("McCain", "Obama")
colnames(my.crosstab) <- c("Male", "Female")
my.crosstab
682/682+697
prop.obama.male <- my.crosstab[2,1]/sum(my.crosstab[,1]) #proportion of males supporting Obama
682/(682+697)
prop.obama.male
697/(682+697)
prop.obama.female <- my.crosstab[2,2]/sum(my.crosstab[,2]) #proportion of females supporting Obama
n.male <- sum(my.crosstab[,1]) #total number of males
n.female <- sum(my.crosstab[,2]) #total number of females
n.male
n.female
n <- n.male + n.female #total number of respondents
n
n.obama <- sum(my.crosstab[2,]) #total number of Obama supporters
n.mccain <- sum(my.crosstab[1,]) #total number of McCain supporters
rep(1, 10)
rep("A", 10)
simulation.results <- numeric(1000000)
box <- c(rep(1, n.obama), rep(0, n.mccain))
box
male.sample <- sample(x=box, size=n.male, replace=TRUE)
male.sample
female.sample <- sample(x=box, size=n.female, replace=TRUE) #same with our female sample
for(i in 1:100000){ #this tells R that we want to do this 1,000,000 times
box <- c(rep(1, n.obama), rep(0, n.mccain)) #this creates our box of the appropriate numbers of obama/mccain supporters
male.sample <- sample(x=box, size=n.male, replace=TRUE) #our male sample is a random sample (w/replacement) from that box
female.sample <- sample(x=box, size=n.female, replace=TRUE) #same with our female sample
male.sample.proportion <- mean(male.sample) #compute the proportion of Obama supporters in the male sample
female.sample.proportion <- mean(female.sample) #same with female supporters
diff <- male.sample.proportion - female.sample.proportion #now we take the difference between the male and female supporters
simulation.results[i] <- diff #and record that in the appropriate position in our vector
} #end of loop
hist(simulation.results)
real.diff <- prop.obama.male - prop.obama.female
our.crosstab.test <- abs(simulation.results) >= abs(real.diff)
our.crosstab.test
mean(our.crosstab.test)
0.5*0.5/sqrt(100)
0.15/0.025
qnorm(0.005)
qnorm(0.995)
pnorm(-2.17, lower.tail = T)
pnorm(-2.17, lower.tail = T)*2
qt(0.025, 9)
3.6-2.262157*0.3858
3.6+2.262157*0.3858
qt(0.005, 9)
3.6-3.249836*0.3858
3.6+3.249836*0.3858
0.23*(1-0.23)/2000
sqrt(0.23*(1-0.23)/2000)
qnorm(0.005)
qnorm(0.005, mean=0, sd=1)
0.23 - 2.575929*0.009410101
0.23 + 2.575929*0.009410101
qnorm(0.05, mean=0, sd=1)
0.23 - 1.644854*0.009410101
0.23 + 1.644854*0.009410101
qnorm(0.025, mean=0, sd=1)
0.23 + 1.959964*0.009410101
0.23 - 1.959964*0.009410101
460/2000
qt(.025, df = 40, lower.tail = FALSE)
6.15+2.021075*-.913
6.15+2.021075*0.913
6.15-2.021075*0.913
pt(6.74, df = 40, lower.tail = F)
pt(6.74, df = 40, lower.tail = F)*2
t.test(MPG.highway[Origin=="USA"], MPG.highway[Origin=="non-USA"])
library(MASS)
data(Cars93)
attach(Cars93)
data.frame(MPG.highway, Origin)
t.test(MPG.highway[Origin=="USA"], MPG.highway[Origin=="non-USA"])
install.packages("cem")
data(LL) # LaLonde's data within cem package
library(cem) # load the library
data(LL) # LaLonde's data within cem package
View(LL)
t.test(LL$re74, mu=6059, alternative="less") # re74: real earnings in 1974
t.test(LL$re74, mu=6059, alternative="less") # re74: real earnings in 1974
t.test(re78~treated,data=LL,alternative="less")
t.test(re78~treated,data=LL,alternative="less") # we are assuming unequal variance
t.test(re78~treated,data=LL,alternative="less", var.equal=T)
install.packages("gmodels")
library(gmodels)
library(MASS)
cont.tbl = table(survey$Smoke, survey$Exer)
table(survey$Smoke, survey$Exer)
CrossTable(y=LL$u75,x=LL$u74,prop.c=F,prop.t=F,
prop.chisq=F,chisq=T)
CrossTable(y=LL$u75,x=LL$u74,prop.c=F,prop.t=F,
prop.chisq=T,chisq=T)
CrossTable(y=LL$u75,x=LL$u74,prop.c=F,prop.t=F,
prop.chisq=F,chisq=T)
cont.tbl = table(survey$Smoke, survey$Exer) # create a contingency table
cont.tbl
chisq.test(cont.tbl)
new.tbl <- cbind(cont.tbl[,"Freq"], cont.tbl[,"None"] + cont.tbl[,"Some"])
new.tbl
chisq.test(new.tbl)
employment.table <- matrix(c(679, 63, 42, 103, 10, 18, 114, 20, 25), ncol=3, nrow=3)
row.names(employment.table) <- c("Employed", "Unemployed", "Not in Labor Force")
colnames(employment.table) <- c("Married", "Divorced", "Never Married")
summary(employment.table)
employment.table <- as.table(employment.table)
summary(employment.table)
summary(employment.table) # This is a matrix of data, and we can get the summary
employment.table <- matrix(c(679, 63, 42, 103, 10, 18, 114, 20, 25), ncol=3, nrow=3)
row.names(employment.table) <- c("Employed", "Unemployed", "Not in Labor Force")
colnames(employment.table) <- c("Married", "Divorced", "Never Married")
summary(employment.table) # This is a matrix of data, and we can get the summary
employment.table <- as.table(employment.table)
summary(employment.table)
employment.table <- matrix(c(679, 63, 42, 103, 10, 18, 114, 20, 25), ncol=3, nrow=3)
row.names(employment.table) <- c("Employed", "Unemployed", "Not in Labor Force")
colnames(employment.table) <- c("Married", "Divorced", "Never Married")
summary(employment.table) # This is a matrix of data, and we can get the summary as we did with dataframe
employment.table
employment.table <- as.table(employment.table)
summary(employment.table)
my.test <- chisq.test(employment.table)
my.test #this appears to just give us the same information as summary
names(my.test)
my.test$p.value
chisq.test(tablename, correct=FALSE)
my.test # we have the same result. just a different function
cont.tbl = table(survey$Smoke, survey$Exer) # create a contingency table
cont.tbl
survey
survey <- data(survey)
survey
data(survey)
survey
cont.tbl = table(survey$Sex, survey$Exer) # create a contingency table
cont.tbl
chisq.test(cont.tbl)
0.15/sqrt(0.5*0.5/100)
library(cem) # load the library
data(LL) # LaLonde's data within cem package
help(LL)
t.test(LL$re74, mu=6059, alternative="less") # re74: real earnings in 1974
t.test(LL$re74, mu=6059)
t.test(LL$re74, mu=6059, var.equal = T)
t.test(LL$re74, mu=6059, var.equal = T, alternative = "less")
library(cem) # load the library
data(LL) # LaLonde's data within cem package
help(LL)
t.test(LL$re74, mu=6059, alternative="less") # re74: real earnings in 1974
t.test(re78~treated,data=LL,alternative="less") # we are assuming unequal variance
library(gmodels)
CrossTable(x, y, expected=TRUE, chisq=T) # if these arguments are true, it is going to add expected values and chi-square test
library(MASS)
library(MASS)
table(survey$Smoke, survey$Exer)
employment.table <- matrix(c(679, 63, 42, 103, 10, 18, 114, 20, 25), ncol=3, nrow=3)
row.names(employment.table) <- c("Employed", "Unemployed", "Not in Labor Force")
colnames(employment.table) <- c("Married", "Divorced", "Never Married")
summary(employment.table) # This is a matrix of data, and we can get the summary as we did with dataframe
employment.table
summary(employment.table) # This is a matrix of data, and we can get the summary as we did with dataframe
employment.table <- as.table(employment.table)
summary(employment.table)
library(MASS)
my.test <- chisq.test(employment.table)
my.test # we have the same result. just a different function
names(my.test)
my.test$expected
my.test$p.value
chisq.test(tablename, correct=FALSE)
library(MASS)
cont.tbl = table(survey$Smoke, survey$Exer) # create a contingency table
cont.tbl
chisq.test(cont.tbl)
new.tbl <- cbind(cont.tbl[,"Freq"], cont.tbl[,"None"] + cont.tbl[,"Some"])
new.tbl
chisq.test(new.tbl)
cont.tbl
new.tbl <- cbind(cont.tbl[,"Freq"], cont.tbl[,"None"] + cont.tbl[,"Some"])
new.tbl
chisq.test(new.tbl)
library(gmodels)
CrossTable(y=LL$u75,x=LL$u74,prop.c=F,prop.t=F,
prop.chisq=F,chisq=T)
t.test(re78~treated,data=LL,alternative="less") # we are assuming unequal variance
-0.13/0.06
-0.13/0.0576
100-12
60-12
60-5.5
60-14
60-8
60-12
-0.12+(1.96*0.0576)
60-3.5
12+10+15+30
67+5
72+10
rbinom(2500)
rbinom(2500, 1)
rbinom(2500, 1 prob=(1/2, 1/2))
rbinom(2500, 2 prob=(1/2, 1/2))
rbinom(2500, 1 prob=c(1/2, 1/2))
simulated.coin.data <- rbinom(n=10000, size=1, prob=1/2)
support.unilpower <- rbinom(n=10000, size=1, prob=1/2)
supportPower <- rbinom(n=10000, size=1, prob=1/2)
t.test(supportPower, mu=0.5)
supportPower <- rbinom(n=10000, size=1, prob=31/100)
t.test(supportPower, mu=0.5)
supportPower <- rbinom(n=2500, size=1, prob=31/100)
t.test(supportPower, mu=0.5)
partyid <- sample(c(1,2,3), size=2500, prob=c(2/5, 1/5, 2/5))
gender <- rbinom(n=2500, size=1, prob=46/100)
partyid <- sample(c(1,2,3), size=2500, prob=c(2/5, 1/5, 2/5))
partyid <- sample(c(1,2,3), size=2500, prob=c(2/5, 1/5, 2/5), replace=TRUE)
gender
partyid
anes <- as.table(gender, partyid)
chisq.test(anes)
summary(anes)
anes <- as.table(gender, partyid)
summary(anes)
anes
gender
partyid
table(partyid)
table(gender)
anes <- as.table(gender, partyid)
anes
table(gender, partyid)
anestable <- table(gender, partyid)
anestable
chisq.test(anestable)
chisq.test(table(gender, partyid))
12+10+15+36+20+10
12+10+15+36+20
x   <- seq(5,15,length=1000)
y   <- df(x,1, 1)
plot(x,y, type="l", lwd=1)
x   <- seq(0,15,length=1000)
y   <- df(x,1, 1)
plot(x,y, type="l", lwd=1)
x   <- seq(0,15,length=1000)
y   <- df(x,1, 1)
plot(x,y, type="l", lwd=1, xlab="", ylab="")
y2   <- df(x,10, 10)
lines(y2, col="red", lwd=2)
y2   <- df(x,90, 10)
lines(y2, col="red", lwd=2)
x   <- seq(0,15,length=1000)
y   <- df(x,1, 1)
plot(x,y, type="l", lwd=1, xlab="", ylab="")
y2   <- df(x,90, 10)
lines(y2, col="red", lwd=2)
x   <- seq(0,4,length=1000)
y   <- df(x,1, 1)
plot(x,y, type="l", lwd=1, xlab="", ylab="")
y2   <- df(x,90, 10)
lines(y2, col="red", lwd=2)
60-2.5-6-3-1-1
60-0.5-2.5-1
60-2.5-2-2-1-2.5-2-1-3-2.5-1
60-2.5-3-5
60-2.5-2-2-1-3-5-4
60-1-1-1-2.5-3-1-1-3-1
60-1-0.5-2-2.5-3-1-4-1
60-3-2-2-4-2-1
60-1-1-2-2-1
60-1.5-1.5-1-0.5-2-2-2-3-4
60-2.5-1-2-1-3-3-4
60-0.5-0.5-2-2-3-4-1
60-3-2-2-3-2-1
60-2-6-3-1
60--4-3
60-7
60-3
library(HistData)
data(GaltonFamilies)
str(GaltonFamilies)
plot(childHeight ~ midparentHeight, GaltonFamilies)
lmod.1 <- lm(childHeight ~ midparentHeight, GaltonFamilies)
coef(lmod)
coef(lmod.1)
abline(lmod.1)
abline(lmod.1, col="red")
cor(midparentHeight, childHeight, GaltonFamilies)
cor(midparentHeight, childHeight, GaltonFamilies, use="complete.obs")
cor(midparentHeight, childHeight, GaltonFamilies, use="everything")
cor(midparentHeight, childHeight, data=GaltonFamilies, use="everything")
cor(GaltonFamilies$midparentHeight, GaltonFamilies$childHeight)
(beta <- with(GaltonFamilies, cor(midparentHeight,childHeight)*sd(childHeight)/sd(midparentHeight)))
(alpha <- with(GaltonFamilies, mean(childHeight) - beta*mean(midparentHeight)))
t.test(envtreat ~ popmill)
summary(lmod.1)
0.63736/0.06161
pnorm(10.34507, lower.tail=F)*2
pnorm(10.34507, lower.tail=F)
pnorm(10.34507, lower.tail=T)
pt(10.34507, lower.tail=F)
pt(10.34507, df=932,lower.tail=F)
pt(10.34507, df=932,lower.tail=F)*2
pt(5.307, df=932,lower.tail=F)*2
pt(10.345, df=932,lower.tail=F)*2
qt(0.975, df=932)
0.63736 + c(-1,1)*1.962513*0.06161
confint(lmod.1)
View(GaltonFamilies)
# Data: Prestige from car package
library(car)
str(Prestige)
summary(Prestige)
prestige.mod = lm(income ~ education, data = newdata)
summary(prestige.mod)
newdata = Prestige[,c(1:2)]
prestige.mod = lm(income ~ education, data = newdata)
plot(newdata$education, prestige.mod$residuals)
lines(h=0, col="lightgrey")
plot(newdata$education, prestige.mod$residuals)
lines(h=0, col="lightgrey")
abline(h=0, col="lightgrey")
plot(prestige.mod, pch=16, which=1) # checking the constant variance assumption
plot(prestige.mod$fitted.values, prestige.mod$residuals)
abline(h=0, col="lightgrey")
100-6.5
93.5*20
93.5*0.2
100-6
94*0.2
100-11.5
88.5*0.2
97.5*0.2
96*0.2
93*0.2
100-3.5
96.5*0.2
100-14
86*0.2
rm(list=ls())
setwd('~/Dropbox/2017_Classes/Text-Analysis/WUSTL/HW/HW2/')
unigram <- read.csv("unigram1000.csv")
setwd('~/Dropbox/2017_Classes/Text-Analysis/WUSTL/HW/HW2/')
unigram <- read.csv("unigram1000.csv")
trigram <- read.csv("trigrams500.csv")
unigram <- read.csv("unigrams1000.csv")
unigram <- read.csv("unigrams1000.csv")
rm(list=ls())
setwd('~/Dropbox/2017_Classes/Text-Analysis/WUSTL/HW/HW2/')
unigram <- read.csv("unigrams1000.csv")
trigram <- read.csv("trigrams500.csv")
rm(list=ls())
setwd('~/Dropbox/2017_Classes/Text-Analysis/WUSTL/HW/HW2/')
unigram <- read.csv("unigrams1000.csv")
trigram <- read.csv("trigrams500.csv")
str(unigram)
str(trigram)
for (i in 1:nrow(unigram)){
s<- sum(uni[i+2,])
uni[i+2,]<- uni[i+2,]/s
}
for (i in 1:nrow(unigram)){
unigram[i+2,]<- unigram[i+2,]/(sum(unigram[i+2,]))
}
subuni <- unigram[,-c(1,2)]
# convert frequencies to rates
for (i in 1:nrow(unigram)){
subuni <- unigram[,-c(1,2)]
subuni[i,]<- subuni[i,]/(sum(subuni[i,]))
}
unigram_rate <- cbind(unigram[,c(1,2)], subuni)
View(unigram_rate)
subuni
head(subuni)
head(unigram)
View(unigram)
View(subuni)
sum(subuni[1,])
subuni[1,]
subuni <- unigram[,-c(1,2)]
subuni[2,]
sum(subuni[2,])
subuni[2,]/sum(subuni[2,])
subuni <- unigram[,-c(1,2)]
for (i in 1:nrow(unigram)){
subuni[i,]<- subuni[i,]/(sum(subuni[i,]))
}
unigram_rate <- cbind(unigram[,c(1,2)], subuni)
head(unigram_rate)
View(unigram_rate)
for (i in 1:nrow(trigram)){
subtri <- trigram[,-c(1,2)]
subtri[i,]<- subtri[i,]/(sum(subtri[i,]))
}
trigram_rate <- cbind(trigram[,c(1,2)], subtri)
meanSpeaker<-with(unigram_rate, tapply(unigram_rate[,-c(1,2)], speaker, mean))
meanSpeaker<-with(unigram_rate, tapply(unigram_rate[,-c(1,2)], speaker, ColMeans))
meanSpeaker<-ColMeans(unigram_rate[,-c(1,2)])
meanSpeaker<-colMeans(unigram_rate[,-c(1,2)])
meanSpeaker<-colMeans(unigram_rate[,-c(1,2)])
meanSpeaker
meanSpeaker<-colMeans(unigram_rate[,-c(1,2)], by=unigram_rate$speaker)
meanSpeaker<-apply(unigram_rate[unigram_rate$speaker, -c(1,2)], 2, mean)
meanSpeaker
varShelby<-apply(unigram_rate[unigram_rate$speaker=="Shelby", -c(1,2)], 2, var)
varSessions <-apply(unigram_rate[unigram_rate$speaker=="Sessions", -c(1,2)], 2, var)
TrimeanShelby<-apply(trigram_rate[trigram_rate$speaker=="Shelby", -c(1,2)], 2, mean)
TrimeanSessions <-apply(trigram_rate[trigram_rate$speaker=="Sessions", -c(1,2)], 2, mean)
TrivarShelby<-apply(trigram_rate[trigram_rate$speaker=="Shelby", -c(1,2)], 2, var)
TrivarSessions <-apply(trigram_rate[trigram_rate$speaker=="Sessions", -c(1,2)], 2, var)
