trainIndex <- createDataPartition(subdat$Species, p=split, list=FALSE)
trainIndex <- createDataPartition(subdat, p=split, list=FALSE)
nrow(subdat)
123*0.6
132*0.6
index <- sample(subdat, 79)
library(caret)
train_control <- trainControl(method="cv", number=1)
grid <- expand.grid(.fL=c(0), .usekernel=c(FALSE))
model <- train(dsk~., data=subdat, trControl=train_control, method="nb", tuneGrid=grid)
install.packages("klaR")
library(caret)
library(klaR)
train_control <- trainControl(method="cv", number=1)
grid <- expand.grid(.fL=c(0), .usekernel=c(FALSE))
model <- train(dsk~., data=subdat, trControl=train_control, method="nb", tuneGrid=grid)
table(subdat$dsk)
train_control <- trainControl(method="LOOCV")
model <- train(dsk~., data=subdat, trControl=train_control, method="nb")
subdat$dsk <- factor(subdat$dsk))
subdat$dsk <- factor(subdat$dsk)
table(subdat$dsk)
library(caret)
library(klaR)
train_control <- trainControl(method="LOOCV")
model <- train(dsk~., data=subdat, trControl=train_control, method="nb")
print(model)
pred <- rep(NA, nrow(subdat))
pred <- rep(NA, nrow(subdat))
for(i in 1:nrow(subdat)){
model <- naiveBayes(subdat$dsk[-i] ~., subdat[-i, ])
pred[i] <- as.character(predict(model, subdat[i, -1]))
}
install.packages("e1071")
train_control <- trainControl(method="LOOCV")
model <- train(dsk~., data=subdat, trControl=train_control, method="nb")
print(model)
model <- naiveBayes(dsk ~ ., data = subdat)
library(e1071)
model <- naiveBayes(dsk ~ ., data = subdat)
class(model)
summary(model)
print(model)
size <- floor(0.65 * nrow(subdat))
set.seed(1234)
library(e1071)
size <- floor(0.65 * nrow(subdat))
train <- sample(seq_len(nrow(subdat)), size = size)
## 65% of the sample size
size <- floor(0.65 * nrow(subdat))
index <- sample(seq_len(nrow(subdat)), size = size)
train <- subdat[index, ]
test <- subdat[-index, ]
model <- naiveBayes(dsk ~ ., data = train)
class(model)
print(model)
preds <- predict(model, newdata = test)
summary(preds)
p <- rep(NA, nrow(subdat))
for(i in 1:nrow(subdat)){
model <- naiveBayes(dsk[i] ~ ., data = subdat)
p[i] <- predict(model, subdat[i, -1])
}
subdat$dsk
model <- naiveBayes(dsk[1] ~ ., data = subdat)
model <- naiveBayes(dsk ~ ., data = subdat)
model <- naiveBayes(dsk[1,] ~ ., data = subdat)
model <- naiveBayes(dsk[,1] ~ ., data = subdat)
model <- naiveBayes(subdat$dsk[-1] ~ ., data = subdat)
View(subdat)
LOOCV <- rep(NA,nrow(subdat))
fit <- train(subdat, subdat$dsk, method = "nb", trControl = trainControl(method = "cv", number = 10))
fit
subdat
head(subdat)
subdat <- subdat[,-c(1,5,6,7)]
head(subdat)
subdat <- subdat[,-c(5)]
head(subdat)
library(klaR)
library(e1071)
set.seed(1234)
library(e1071)
fit <- train(subdat, subdat$dsk, method = "nb", trControl = trainControl(method = "cv", number = 10))
fit
fit <- train(subdat, subdat$dsk, method = "nb", trControl = trainControl(method = "cv", number = 1))
fit <- train(subdat, subdat$dsk, method = "nb", trControl = trainControl(method = "cv", number = 3))
fit
fit <- train(subdat, subdat$dsk, method = "nb", trControl = trainControl(method = "cv", number = 10))
fit
size <- floor(0.65 * nrow(subdat))
index <- sample(seq_len(nrow(subdat)), size = size)
train <- subdat[index, ]
test <- subdat[-index, ]
train_control <- trainControl(method="cv", number=10)
fit <- train(train, test, method = "nb",trControl=train_control)
fit
size <- floor(0.65 * nrow(subdat))
index <- sample(seq_len(nrow(subdat)), size = size)
train <- subdat[index, ]
test <- subdat[-index, ]
train_control <- trainControl(method="cv", number=10)
fit <- train(train, test, method = "nb",trControl=train_control)
size <- 0.65 * nrow(subdat)
index <- sample(seq_len(nrow(subdat)), size = size)
train <- subdat[index, ]
test <- subdat[-index, ]
train_control <- trainControl(method="cv", number=10)
fit <- train(train, test, method = "nb",trControl=train_control)
fit
size
size <- floor(0.65 * nrow(subdat))
index <- sample(seq_len(nrow(subdat)), size = size)
index
train <- subdat[index, ]
test <- subdat[-index, ]
train_control <- trainControl(method="cv", number=10)
traindat <- subdat[index, ]
test <- subdat[-index, ]
train_control <- trainControl(method="cv", number=10)
fit <- train(traindat, test, method = "nb",trControl=train_control)
size <- floor(0.65 * nrow(subdat))
index <- sample(seq_len(nrow(subdat)), size = size)
traindat <- subdat[index, ]
test <- subdat[-index, ]
train_control <- trainControl(method="cv", number=10)
fit <- train(traindat, test$dsk, method = "nb",trControl=train_control)
fit
fit <- train(traindat$dsk, test$dsk, method = "nb",trControl=train_control)
fit
fit <- train(test$dsk, train, method = "nb",trControl=train_control)
fit
levels(subdat$dsk) <- make.names(levels(factor(subdat$dsk)))
train_control <- trainControl(method="cv", number=10)
fit <- train(test$dsk, train, method = "nb",trControl=train_control)
fit <- train(test, train, method = "nb",trControl=train_control)
fit <- train(train, test$dsk, method = "nb",trControl=train_control)
fit
fit <- train(train$dsk, test$dsk, method = "nb",trControl=train_control)
fit
size <- floor(0.65 * nrow(subdat))
index <- sample(seq_len(nrow(subdat)), size = size)
levels(subdat$dsk) <- make.names(levels(factor(subdat$dsk)))
traindat <- subdat[index, ]
test <- subdat[-index, ]
train_control <- trainControl(method="cv", number=10)
fit <- train(train$dsk, test$dsk, method = "nb",trControl=train_control)
fit
model <- naiveBayes(train$dsk ~.,data=train)
predict(model, test, type = "raw")
model <- naiveBayes(subdat$dsk[-1] ~.,data=subdat)
subdat$dsk
subdat$dsk[-100]
model <- naiveBayes(subdat[-1]~.,data=subdat)
model <- naiveBayes(subdat[-1,]~.,data=subdat)
subdat
subdat[-100]
for(i in 1:nrow(subdat)){
model <- naiveBayes(subdat$dsk[-i] ~.,data=subdat[-i,])
p[i] <- predict(model, subdat[i,], type = "raw")
}
p
sum(p == subdat$desk)/nrow(subdat) ## 88% accuracy!
for(i in 1:nrow(subdat)){
model <- naiveBayes(subdat$dsk[-i] ~.,data=subdat[-i,])
p[i] <- as.character(predict(model, subdat[i,], type = "raw"))
}
p
mean(p)
for(i in 1:nrow(subdat)){
model <- naiveBayes(subdat$dsk[-i] ~.,data=subdat[-i,])
p[i] <- predict(model, subdat[i,], type = "raw")
}
mean(p)
for(i in 1:nrow(subdat)){
model <- naiveBayes(subdat$dsk[-i] ~.,data=subdat[-i,])
p[i] <- predict(model, subdat[i,], type = "raw")
}
p
for(i in 1:nrow(subdat)){
model <- naiveBayes(subdat$dsk[-i] ~.,data=subdat[-i,])
p[i] <- as.numeric(predict(model, subdat[i,], type = "raw"))
}
mean(p)
p
rm(list=ls())
setwd('~/Dropbox/2017_Classes/Text-Analysis/WUSTL/HW/HW3/')
NYTimes <- read.csv("NYTAnalysis.csv", header=T,row.names=NULL)
str(NYTimes)
NYTimes$election <- NA
NYTimes$election[NYTimes$pubdate==1] <- 0
NYTimes$election[NYTimes$pubdate!=1] <- 1
NYTimes$election <- as.factor(NYTimes$election)
NYTimes$positive <- -(NYTimes$Difference)
mod1 <- lm(Difference ~ election + dsk, NYTimes)
summary(mod1)
table(NYTimes$dsk)
subdat <- subset(NYTimes, NYTimes$dsk=="Business/Financial Desk" | NYTimes$dsk=="National Desk")
table(subdat$dsk)
subdat$dsk <- factor(subdat$dsk)
table(subdat$dsk)
head(subdat)
subdat <- subdat[,-c(1,5,6,7)]
subdat <- subdat[,-c(5)]
library(caret)
library(klaR)
library(e1071)
set.seed(1234)
library(e1071)
size <- floor(0.65 * nrow(subdat))
index <- sample(seq_len(nrow(subdat)), size = size)
levels(subdat$dsk) <- make.names(levels(factor(subdat$dsk)))
traindat <- subdat[index, ]
test <- subdat[-index, ]
model <- naiveBayes(train$dsk ~.,data=train)
model <- naiveBayes(train ~.,data=train)
model <- naiveBayes(traindat$dsk ~.,data=train)
model <- naiveBayes(traindat$dsk ~.,data=train)
traindat <- as.data.frame(subdat[index, ])
test <- subdat[-index, ]
model <- naiveBayes(traindat$dsk ~.,data=train)
model <- naiveBayes(traindat ~.,data=train)
for(i in 1:nrow(subdat)){
model <- naiveBayes(subdat$dsk[-i] ~.,data=subdat[-i,])
p[i] <- predict(model, subdat[i,], type = "raw")
}
p <- rep(NA, nrow(subdat))
for(i in 1:nrow(subdat)){
model <- naiveBayes(subdat$dsk[-i] ~.,data=subdat[-i,])
p[i] <- predict(model, subdat[i,], type = "raw")
}
p
mean(p)
set.seed(1234)
size <- floor(0.65 * nrow(subdat))
index <- sample(seq_len(nrow(subdat)), size = size)
levels(subdat$dsk) <- make.names(levels(factor(subdat$dsk)))
traindat <- as.data.frame(subdat[index, ])
test <- subdat[-index, ]
fit.lasso <- glmnet(traindat, test$dsk, family="gaussian", alpha=1)
fit.ridge <- glmnet(x.train, y.train, family="gaussian", alpha=0)
library(MASS)  # Package needed to generate correlated precictors
library(glmnet)  # Package to fit ridge/lasso/elastic net models
fit.lasso <- glmnet(traindat, test$dsk, family="gaussian", alpha=1)
fit.ridge <- glmnet(x.train, y.train, family="gaussian", alpha=0)
fit.lasso <- cv.glmnet(traindat, test$dsk, family="gaussian", alpha=1)
fit.lasso <- cv.glmnet(traindat, traindat$dsk, family="gaussian", alpha=1)
View(traindat)
fit.lasso <- cv.glmnet(traindat[,-3], traindat$dsk, family="gaussian", alpha=1)
fit.lasso <- cglmnet(traindat[,-3], traindat$dsk, family="gaussian", alpha=1)
fit.lasso <- glmnet(traindat[,-3], traindat$dsk, family="gaussian", alpha=1)
traindat$dsk
fit.lasso <- glmnet(traindat[,-3], as.factor(traindat$dsk), family="gaussian", alpha=1)
fit.lasso <- glmnet(traindat[,-3], as.factor(traindat$dsk), family="gaussian", alpha=1,family = "binomial")
fit.lasso <- glmnet(traindat[,-3], as.factor(traindat$dsk), alpha=1,family = "binomial")
fit.lasso <- glmnet(x=traindat[,-3], y=as.factor(traindat$dsk), alpha=1,family = "binomial")
View(subdat)
View(subdat)
p <- rep(NA, nrow(subdat))
for(i in 1:nrow(subdat)){
model <- naiveBayes(subdat$dsk[-i] ~.,data=subdat[-i,])
p[i] <- predict(model, subdat[i,-3], type = "raw") # raw will give me a probability
}
mean(p) # average prediction
0.4282862 # does this mean naive bayes predicted about 43%?
p <- rep(NA, nrow(subdat))
for(i in 1:nrow(subdat)){
model <- naiveBayes(subdat$dsk[-i] ~.,data=subdat[-i,])
p[i] <- predict(model, subdat[i,-3], type = "raw") # raw will give me a probability
}
mean(p) # average prediction
0.4282862 # does this mean naive bayes predicted about 43%?
size <- floor(0.65 * nrow(subdat))
index <- sample(seq_len(nrow(subdat)), size = size)
levels(subdat$dsk) <- make.names(levels(factor(subdat$dsk)))
traindat <- as.data.frame(subdat[index, ])
test <- subdat[-index, ]
library(MASS)
library(glmnet)
yhat0 <- predict(fit.lasso, s=fit.lasso$lambda.1se, newx=test)
fit.lasso.cv <- cv.glmnet(x=traindat[,-3], as.factor(traindat$dsk), type.measure="mse", alpha=1,
family="binomial")
set.seed(19873)
n <- 100    # Number of observations
p <- 50     # Number of predictors included in model
CovMatrix <- outer(1:p, 1:p, function(x,y) {.7^abs(x-y)})
x <- mvrnorm(n, rep(0,p), CovMatrix)
y <- 10 * apply(x[, 1:2], 1, sum) +
5 * apply(x[, 3:4], 1, sum) +
apply(x[, 5:14], 1, sum) +
rnorm(n)
# Split data into train and test sets
train_rows <- sample(1:n, .66*n)
x.train <- x[train_rows, ]
x.test <- x[-train_rows, ]
y.train <- y[train_rows]
y.test <- y[-train_rows]
x.train
x.test
y.train
size <- floor(0.65 * nrow(subdat))
index <- sample(seq_len(nrow(subdat)), size = size)
levels(subdat$dsk) <- make.names(levels(factor(subdat$dsk)))
traindat <- as.data.frame(subdat[index,-3])
test <- subdat[-index,-3]
y.train <- traindat$dsk
y.test <- test$dsk
traindat
y.test <- subdat[-index,3]
y.train <- as.data.frame(subdat[index,3])
y.test
fit.lasso.cv <- cv.glmnet(x=traindat, as.factor(y.train), type.measure="mse", alpha=1,
family="binomial")
fit.lasso.cv <- cv.glmnet(x=traindat, factor(y.train), type.measure="mse", alpha=1,
family="binomial")
fit.lasso.cv <- cv.glmnet(x=traindat, factor[y.train], type.measure="mse", alpha=1,
family="binomial")
y.train <- factor(subdat[index,3])
fit.lasso.cv <- cv.glmnet(x=traindat, y.train, type.measure="mse", alpha=1,
family="binomial")
y.train
levels(y.train)
fit.lasso.cv <- cv.glmnet(x=traindat, y.train, type.measure="mse", alpha=1,
family="binomial")
traindat <- as.matrix(subdat[index,-3])
test <- subdat[-index,-3]
y.train <- factor(subdat[index,3])
y.test <- subdat[-index,3]
library(MASS)
library(glmnet)
fit.lasso.cv <- cv.glmnet(x=traindat, y.train, type.measure="mse", alpha=1,
family="binomial")
traindat
traindat <- as.numeric(traindat)
fit.lasso.cv <- cv.glmnet(x=traindat, y.train, type.measure="mse", alpha=1,
family="binomial")
fit.lasso.cv <- cv.glmnet(x=traindat, y.train, type.measure="mse", alpha=1,
family="binomial")
fit.ridge.cv <- cv.glmnet(traindat, y.train, type.measure="mse", alpha=0,
family="binomial")
pred.lasso <- predict(fit.lasso.cv, s=y.test, newx=test)
pred.ridge <- predict(fit.ridge.cv, s=y.test, newx=test)
traindat
traindat <- as.matrix(subdat[index,-3])
traindat
traindat <- data.matrix(subdat[index,-3])
traindat
fit.lasso.cv <- cv.glmnet(x=traindat, y.train, type.measure="mse", alpha=1,
family="binomial")
fit.ridge.cv <- cv.glmnet(traindat, y.train, type.measure="mse", alpha=0,
family="binomial")
pred.lasso <- predict(fit.lasso.cv, s=y.test, newx=test)
pred.ridge <- predict(fit.ridge.cv, s=y.test, newx=test)
y.test <- factor(subdat[-index,3])
pred.lasso <- predict(fit.lasso.cv, y.test, newx=test)
pred.ridge <- predict(fit.ridge.cv, y.test, newx=test)
fit.lasso.cv <- cv.glmnet(x=traindat, y.train, type.measure="mse", alpha=1,
family="binomial")
fit.ridge.cv <- cv.glmnet(traindat, y.train, type.measure="mse", alpha=0,
family="binomial")
pred.lasso <- predict(fit.lasso.cv, y.test, newx=test)
test <- data.matrix(subdat[-index,-3])
pred.lasso <- predict(fit.lasso.cv, y.test, newx=test)
pred.ridge <- predict(fit.ridge.cv, y.test, newx=test)
pred.lasso <- predict(fit.lasso.cv, newx=test)
pred.ridge <- predict(fit.ridge.cv, newx=test)
pred.lasso
test
fit.lasso <- glmnet(x=traindat, y.train, type.measure="mse", alpha=1,
family="binomial")
fit.lasso <- glmnet(x=traindat, y.train, alpha=1,
family="binomial")
fit.ridge <- glmnet(traindat, y.train,alpha=0,
family="binomial")
par(mfrow=c(1,2))
plot (fit.lasso.cv); plot (fit.ridge.cv)
plot (log (fit.lasso.cv$lambda), fit.lasso.cv$cvm, pch= 10, col="red", xlab = "log(Lambda)", ylab= fit.lasso.cv$name)
points(log(fit.ridge.cv$lambda), fit.ridge.cv$cvm, pch= 10, col = "blue")
legend ("topleft", legend = c("alpha=1", "alpha= 0"), pch= 19, col = c("red",  "blue"))
par(mfrow=c(1,2))
plot (fit.lasso.cv); plot (fit.ridge.cv)
plot (log (fit.lasso.cv$lambda), fit.lasso.cv$cvm, pch= 10, col="red", xlab = "log(Lambda)", ylab= fit.lasso.cv$name)
points(log(fit.ridge.cv$lambda), fit.ridge.cv$cvm, pch= 10, col = "blue")
legend ("topleft", legend = c("alpha=1", "alpha= 0"), pch= 19, col = c("red",  "blue"))
plot (fit.lasso.cv); plot (fit.ridge.cv)
plot (log (fit.lasso.cv$lambda), fit.lasso.cv$cvm, pch= 10, col="red", xlab = "log(Lambda)", ylab= fit.lasso.cv$name)
points(log(fit.ridge.cv$lambda), fit.ridge.cv$cvm, pch= 10, col = "blue")
plot (fit.lasso.cv)
par(mfrow=c(2,2))
plot (fit.lasso.cv)
plot (fit.ridge.cv)
plot (log (fit.lasso.cv$lambda), fit.lasso.cv$cvm, pch= 10, col="red", xlab = "log(Lambda)", ylab= fit.lasso.cv$name)
points(log(fit.ridge.cv$lambda), fit.ridge.cv$cvm, pch= 10, col = "blue")
legend ("topleft", legend = c("alpha=1", "alpha= 0"), pch= 19, col = c("red",  "blue"))
yhat0 <- predict(fit.lasso.cv, s=fit.lasso.cv$lambda.1se, newx=test)
yhat1 <- predict(fit.ridge.cv, s=fit.ridge.cv$lambda.1se, newx=test)
mse.lasso <- mean((y.test - yhat0)^2)
mse.ridge <- mean((y.test - yhat1)^2)
yhat1
fit.lasso.cv <- cv.glmnet(x=traindat, y.train, type.measure="mse", alpha=1,
family="binomial")
fit.lasso.cv
test
yhat0
length(yhat0)
y.test
y.train <- factor(recode(y.train,"Business.Financial.Desk"=0;"National.Desk"=1))
y.train <- factor(recode(y.train,"Business.Financial.Desk"=0,"National.Desk"=1))
library(car)
y.train <- factor(recode(y.train,"Business.Financial.Desk"=0,"National.Desk"=1))
y.train <- factor(recode(y.train,"Business.Financial.Desk"==0,"National.Desk"==1))
y.train
size <- floor(0.65 * nrow(subdat))
index <- sample(seq_len(nrow(subdat)), size = size)
levels(subdat$dsk) <- make.names(levels(factor(subdat$dsk)))
traindat <- data.matrix(subdat[index,-3])
test <- data.matrix(subdat[-index,-3])
y.train <- factor(subdat[index,3])
y.train <- contrasts(as.factor(y.train))
y.train
test <- data.matrix(subdat[-index,-3])
y.train <- factor(subdat[index,3])
y.train <- contrasts(as.factor(y.train))
y.test <- factor(subdat[-index,3])
y.test <- contrasts(as.factor(y.test))
library(MASS)
library(glmnet)
fit.lasso <- glmnet(x=traindat, y.train, alpha=1,
family="binomial")
fit.ridge <- glmnet(traindat, y.train,alpha=0,
family="binomial")
fit.lasso.cv <- cv.glmnet(x=traindat, y.train, type.measure="mse", alpha=1,
family="binomial")
size <- floor(0.65 * nrow(subdat))
index <- sample(seq_len(nrow(subdat)), size = size)
levels(subdat$dsk) <- make.names(levels(factor(subdat$dsk)))
traindat <- data.matrix(subdat[index,-3])
test <- data.matrix(subdat[-index,-3])
y.train <- factor(subdat[index,3])
y.train <- function(x) {as.numeric(levels(x))[y.train]}
y.train
y.train <- function(x) {as.numeric(levels(y.train))[y.train]}
y.train
y.train <- factor(subdat[index,3])
y.train <- as.numeric(as.character(y.train))
y.train
y.train <- factor(subdat[index,3])
y.train <- within(y.train, {
class <- as.numeric(as.character(y.train))
})
y.train <- factor(subdat[index,3])
y.train<-as.factor(y.train)
t.train
y.train
y.train <- as.numeric(as.character(y.train))
y.train <- factor(subdat[index,3])
y.train<-as.factor(y.train)
y.train <- as.numeric(y.train)
y.train
y.train <- as.numeric(y.train)-1
y.train <- factor(subdat[index,3])
y.train <- as.numeric(y.train)-1
y.train
y.test <- as.numeric(y.test)-1
library(MASS)
library(glmnet)
fit.lasso <- glmnet(x=traindat, y.train, alpha=1,
family="binomial")
fit.ridge <- glmnet(traindat, y.train,alpha=0,
family="binomial")
fit.lasso.cv <- cv.glmnet(x=traindat, y.train, type.measure="mse", alpha=1,
family="binomial")
fit.ridge.cv <- cv.glmnet(traindat, y.train, type.measure="mse", alpha=0,
family="binomial")
yhat0 <- predict(fit.lasso.cv, s=fit.lasso.cv$lambda.1se, newx=test)
yhat1 <- predict(fit.ridge.cv, s=fit.ridge.cv$lambda.1se, newx=test)
mse.lasso <- mean((y.test - yhat0)^2)
yhat0
y.test
y.test <- factor(subdat[-index,3])
y.test
as.numeric(y.test)
test <- data.matrix(subdat[-index,-3])
y.train <- factor(subdat[index,3])
y.train <- as.numeric(y.train)-1
y.test <- factor(subdat[-index,3])
y.test <- as.numeric(y.test)
library(MASS)
library(glmnet)
fit.lasso <- glmnet(x=traindat, y.train, alpha=1,
family="binomial")
fit.ridge <- glmnet(traindat, y.train,alpha=0,
family="binomial")
fit.lasso.cv <- cv.glmnet(x=traindat, y.train, type.measure="mse", alpha=1,
family="binomial")
fit.ridge.cv <- cv.glmnet(traindat, y.train, type.measure="mse", alpha=0,
family="binomial")
yhat0 <- predict(fit.lasso.cv, s=fit.lasso.cv$lambda.1se, newx=test)
yhat1 <- predict(fit.ridge.cv, s=fit.ridge.cv$lambda.1se, newx=test)
mse.lasso <- mean((y.test - yhat0)^2)
mse.ridge <- mean((y.test - yhat1)^2)
mse.lasso
mse.ridge <- mean((y.test - yhat1)^2)
mse.ridge
yhat0
yhat0
y.test
y.test-1
mse.lasso <- mean(((y.test-1) - yhat0)^2)
mse.lasso
mse.ridge <- mean(((y.test-1) - yhat1)^2)
mse.ridge
